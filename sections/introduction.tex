\chapter{Introduction}\label{cha:intro}

TODO: This is the most important chapter writing wise since this is the part most diverse people will read.

In computer graphics one of the most important parts of making a scene look realistic is the lighting. Realistic illumination has been a goal of 3D rendering since the beginning. But there is still a lot of work to do, especially when it comes to real-time solutions.

It roots objects and creates depth in a scene by creating shadows. Light also gives information about materials by interacting with the objects. 

\section{Motivation}

TODO: This text should be very easy to understand and be intriguing for the reader.

Illumination of a scene in computer graphics is a complex task. When real light shines on a scene, it bounces and objects in the scene becomes indirect light sources. These brighten objects in the scene on sides with no direct view of the light. By approximating the effects of this behavior rendering scenes in real time is possible. 
A common approach is to use advanced lighting algorithms and store the results. The actual rendering uses these results instead of doing expensive calculations. This makes it possible to render realistic looking static scenes in real time. 

Approximating shadows from indirect light is usually solved by Ambient Occlusion. The goal of this method is to make corners and tight spaces darker since they should receive less light.

Global Illumination algorithms tries to simulate both direct and indirect light effects.  

Rendering using, for example Photon Mapping, makes it possible to create direct and indirect light (both diffuse and specular), caustics and shadows making it one of the more popular techniques for off-line rendering when high quality is needed, because it converges toward a correct solution when more photons are used.

\section{Purpose}

TODO: This text can be a little more technical but should lead up to the questions in the next section.

Most solutions for \gls{gi}~\cite{sotagi} does not run in real-time (or even interactive frame-rates), but in the recent years due to hardware performance increase and novel methods (especially \gls{vct}), real time solutions to \gls{gi} has been demonstrated on high-end hardware. 

Since the hardware in mobile devices are making great progress (still far from high-end desktop solutions) and since it has already been proven once~\cite{gimobile} it is interesting to see how far the latest mobile generation can push global illumination on limited hardware.

Especially since \gls{vr} and \gls{ar} are making an entrance to the entertainment scene.
There it would be of huge value if the devices that we put on our heads manage to produce impressive graphics without having to rely on server side graphics like described in~\cite{cloudlight} or even cables from a local machine. 
While the idea of calculating graphics and lighting on a server and basically streaming the content to clients is very interesting, it does have a lot of limiting factors mainly when it comes to network connection and mobility.

Investigating where the limit is on this generations mobile devices is therefore still an important and interesting question.

\section{Problem Statement}

TODO: Don't answer the questions here. Move answers to later chapters

\begin{itemize}
  \item \textit{Is \acrlong{gi} on mobile devices possible using modern hardware?}
\end{itemize}

Previous results from~\cite{gimobile} show that \gls{gi} in real-time is possible on mobile devices using \glspl{vpl}. 
Even though the results are quite recent the pace of improvement in mobile computational power means that there should be room for more advanced approaches, like \gls{vct}.

\begin{itemize}
  \item \textit{Is there a method for \acrlong{gi} that scale well enough to be used on limited hardware such as a mobile device?}
\end{itemize}

\gls{vct} have parameters that can be tuned between speed and quality. 
The number of cones and their angles makes a large difference for the result both in the quality and speed but also different effects. 
The voxelization in particular can make a large difference for the performance, from using a static scene and no per frame updates to voxelizing the complete scene per frame.

\begin{itemize}
  \item \textit{What are the limiting factors of the mobile device? And are there any potential benefits on using mobile devices for \gls{gi}?}
\end{itemize}

The hardware structure on the mobile platforms are quite different from desktop hardware. 
Using a combined memory model and very limited shared memory (if any) between \gls{gpu} cores makes it necessary to adapt the code and the algorithms used.

\section{Limitations}

TODO: Make point list and maybe a short and concise reasoning for why.

Only devices capable of running \gls{ogles} 3.1 + \gls{aep}, or later, will be targeted for development. This limitation is because the implementation requires geometry shaders which is not present for earlier versions. 
Vulcan was considered and rejected because it would require too much work, which is better spent on the main algorithm, and since the algorithm is mainly \gls{gpu} bound it would not significantly increase the performance.

Android is the mobile platform of choice, since it supports both \gls{ogles}, \gls{ocl} and Vulcan (for future improvements). 
Android \acrshort{api} level 23 will be used partly because only the later versions have support for \gls{ogles} 3.1+ (requires API 21+) and it also means no time have to be spent on supporting older functionality in Android.

The algorithm will be evaluated on a Samsung S7 Edge which features the Mali T880 MP12 \gls{gpu}. 
If possible it would be great to compare performance on a device with a Snapdragon 820 chip-set featuring an Adreno 530 \gls{gpu}. These are the two latest \glspl{gpu} on the mobile market and it would make for an interesting comparison. 
Unfortunately iOS does not support \gls{ogles} past 3.0 and also does not have support for geometry shaders in Metal which is required for the suggested approach.

The first priority for the \gls{vct} algorithm will be speed, so that a scene of reasonable size can be rendered in 30 fps on latest mobile hardware, using \gls{vct} for \gls{ao}, direct light, soft shadows, indirect light and specular light. 
The second priority will be to make the scene as dynamic as possible, allowing both dynamic lights and dynamic objects. 
The third priority will be to decrease any potential graphical glitches and increase the visual quality of the scene. 